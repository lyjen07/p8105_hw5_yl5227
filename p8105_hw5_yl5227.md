p8105_hw5_yl5227
================
Jennifer Li
2023-11-15

# Problem 1

Import dataset, create variable.

``` r
df_homocide = 
  read_csv("data/homicide-data.csv", na = c("", "NA", "Unknown")) |> 
  mutate(
    city_state = str_c(city, state, sep = ", "),
    status = case_when(
      disposition == "Closed without arrest" ~ "unsolved",
      disposition == "Open/No arrest" ~ "unsolved",
      disposition == "Closed by arrest" ~ "solved",
      ))
```

    ## Rows: 52179 Columns: 12
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (8): uid, victim_last, victim_first, victim_race, victim_sex, city, stat...
    ## dbl (4): reported_date, victim_age, lat, lon
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

This dataset gathered data on homicides in 50 large U.S. cities. The
resulting dataframe has 52179 entries, on variables that include the
victim name, race, age, and sex; the date the homicide was reported; and
the location of the homicide. In cleaning, I created a `city_state`
variable that includes both city and state, and a `status` variable to
indicate whether the case was closed by arrest. I also excluded one
entry in Tulsa, AL, which is not a major US city and is most likely a
data entry error.

Let’s summarize total number of homicides and unsolved homicides within
cities.

``` r
df_city_homcide =
  df_homocide |> 
  select(city_state, status) |> 
  summarize(
    total_homocide = n(),
    unsolved_homocide = sum(status == "unsolved"))
```

# Problem 2

This zip file contains data that allows tracking of changes in
observations over multiple weeks for each subject within their assigned
group.

Create a tidy dataframe containing data from all participants, including
the subject ID, arm, and observations over time.

``` r
df_all_participants =
  tibble(
    file_names = list.files(path = "data", pattern = "(con|exp)_\\d\\d.csv", full.names = TRUE),
    data = map(file_names, read_csv)) |> 
  separate(file_names, into = c("group", "subject_id"), sep = "\\_") |> 
  mutate(
    group = str_remove(group, "data/"),
    subject_id = str_remove(subject_id, ".csv")
  ) |> 
  unnest(data) |> 
  pivot_longer(
    week_1:week_8,
    names_to = "week",
    names_prefix = "week_",
    values_to = "value"
  ) |> 
  mutate(week = as.numeric(week))

df_all_participants
```

    ## # A tibble: 160 × 4
    ##    group subject_id  week value
    ##    <chr> <chr>      <dbl> <dbl>
    ##  1 con   01             1  0.2 
    ##  2 con   01             2 -1.31
    ##  3 con   01             3  0.66
    ##  4 con   01             4  1.96
    ##  5 con   01             5  0.23
    ##  6 con   01             6  1.09
    ##  7 con   01             7  0.05
    ##  8 con   01             8  1.94
    ##  9 con   02             1  1.13
    ## 10 con   02             2 -0.88
    ## # ℹ 150 more rows

The provided dataframe `df_all_participants` contains longitudinal data
from a study with both control and experimental groups. It has a total
of 160 entries, structured on variables that include `group` to specify
the arm (control or experimental), `subject_id` for participant
identification, `week` to denote the time point of the observation, and
`value` representing the measurement or observation recorded. Each
participant’s data is compiled in a distinct file, named with their
respective subject ID and group designation.

Make a spaghetti plot

``` r
df_all_participants |> 
  ggplot(aes(x = week, y = value, group = str_c(subject_id,group), color = group)) +
  geom_line() +
  labs(title = "Values on each Subject Over Time")
```

<img src="p8105_hw5_yl5227_files/figure-gfm/unnamed-chunk-4-1.png" width="90%" />

In the control group, the data points for each participant remain
relatively stable, showing little change over time. However, in the
experimental group, there’s a clear pattern of growth, with measurements
for each subject showing an upward trajectory with each passing week.

# Problem 3

Set a seed for reproducibility

``` r
set.seed(12345)
```

Write a function to perform a one-sample t-test on 5000 independent
datasets from a normal distribution with parameters of `mu` = 0, `sigma`
= 5, `n`= 30, and a significance level of 0.05.

``` r
one_sample_t_test = function(mu = 0, sigma = 5, n = 30, num_sample = 5000){
  dataset = 
    map(.x = rep(mu, num_sample), .f = ~tibble(data=rnorm(n,.x,sigma))) |>
    map(t.test) |>
    map_df(broom::tidy)

  p_rej = dataset |>
    filter(p.value < 0.05) |>
    nrow() %>%
    `/`(num_sample)

  mu_est = dataset |>
    pull(estimate) |>
    mean()
  
  mu_rej = dataset |>
    filter(p.value < 0.05) |>
    pull(estimate) |>
    mean()
  
  tibble(mu = mu, p_rej = p_rej, mu_est = mu_est, mu_rej = mu_rej)
}
```

Iterating the function for `mu` ={0,1,2,3,4,5,6}:

``` r
exp_res = 
  0:6 |>
  map_df(one_sample_t_test)

exp_res
```

    ## # A tibble: 7 × 4
    ##      mu  p_rej  mu_est mu_rej
    ##   <int>  <dbl>   <dbl>  <dbl>
    ## 1     0 0.0468 0.00590  0.214
    ## 2     1 0.183  1.01     2.27 
    ## 3     2 0.539  1.98     2.63 
    ## 4     3 0.879  2.99     3.20 
    ## 5     4 0.988  4.00     4.02 
    ## 6     5 1      5.02     5.02 
    ## 7     6 1      6.01     6.01

Then, make a plot for the percentage of samples where null was rejected
p\<0.05.

``` r
exp_res |>
  ggplot(aes(x = mu,y = p_rej)) +
  geom_line() +
  scale_y_continuous(labels = scales::percent_format(scale = 100)) +
  scale_x_continuous(breaks = 0:6) +
  ylab("percentage of rejection") +
  labs(title = "Percentage of Rejection over Different mu")
```

<img src="p8105_hw5_yl5227_files/figure-gfm/unnamed-chunk-8-1.png" width="90%" />

Obviously, with the increase of `mu`, the power of the test increased
quickly, and saturated at about `mu`=5. It is also notable that when
`mu`= 0, the percentage of rejection is not the power of the test, but
the percentage of type-I error, because the null hypothesis is true.

Finally, make a plot showing the comparison of `estimated mu` between
all and rejected samples.

``` r
exp_res |>
  pivot_longer(
    mu_est:mu_rej,
    names_to = "mu_type",
    values_to = "mu_est"
  ) |>
  ggplot(aes(x = mu, y = mu_est, color = mu_type)) +
  geom_line() +
  scale_color_discrete(labels = c("all", "rejected")) +
  scale_x_continuous(breaks = 0:6) +
  ylab("estimated mu") +
  labs(title = "Comparison of estimated mu between all and rejected samples")
```

<img src="p8105_hw5_yl5227_files/figure-gfm/unnamed-chunk-9-1.png" width="90%" />

Because the number of rejected samples is low when `mu`=0, the estimated
mu for rejection is quite unstable around 0.

For `mu` = {1,2,3,4,5,6}, `mu_rej` is higher than `mu_all`. However, the
gap `mu_rej` - `mu_all` gradually decreases with the increase of `mu`.
Because when `mu` is equal or greater than 5, nearly all samples are
rejected, `mu_rej` approximately equals to `mu_all` under such
conditions.
